
[audio]
sampling_rate = 44100
hop_length = 128

bins_per_octave = 48
num_octaves = 8
cqt_fmin = A1
cqt_bit_depth = float32

n_iter = 4

[dataset]
datapath = /mimer/NOBACKUP/groups/ml-music/datasets/lts-pytorch/fsd50k-c-lts
cqt_dataset = npy
test_dataset = test_audio
generate_test = True
overwrite_cqt = True
check_audio = True
check_dataset = True
workspace = 
run_number = 0
total_frames = 

[VAE]
latent_dim = 256
n_units = 2048
kl_beta = 0.0005
device = cuda:0

[training]
epochs = 5000
save_best_model_after = 50
learning_rate = 0.00005
batch_size = 1024
checkpoint_interval = 200

[notes]
additional_notes = IT WORKS! checking with fsd50k-by-cc

[extra]
normalize_examples = True
example_length = 10
plot_model = True

description = alvis
start = 
end = 
time_elapsed = 
